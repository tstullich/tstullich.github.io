[{"categories":null,"content":"This is the first post in a series following my development on a deferred renderer in Vulkan. The code can also be used as a base to build other applications.","date":"01-09-2020","objectID":"/posts/vulkan-sandbox/","tags":["computer-graphics","vulkan","dear-imgui"],"title":"A Vulkan + Dear ImGui Sandbox","uri":"/posts/vulkan-sandbox/"},{"categories":null,"content":"Overview For my first technical post I wanted to write about a topic that I have been trying to improve myself in for quite some time - Vulkan. Compared to other APIs that interface with GPUs, Vulkan chooses to be overly explicit to give programmers full control of how their application behaves. This extra verbosity makes the API very appealing for writing high-performance applications, because the device driver will have to deal with less overhead when running the appliction on the GPU. However, this comes with the caveat that a lot more boilerplate code is required from the user to configure a rendering pipeline. So if you are a newcomer to Vulkan and have attempted to write your own renderer using Vulkan, you must have quickly realized how much code it takes to even get a single triangle rendered on screen. Personally, this was always a large barrier to entry for learning Vulkan, but after a couple of running starts I believe I have finally overcome this problem. Now I want to make it easier for other newcomers to developing applications for Vulkan. This is why I have created a small sandbox application, which is just a very basic version of Vulkan application that should allow anyone to get started writing Vulkan code. The codebase includes all of the logic to create a graphics pipeline with Vulkan to render a triangle on screen and also integrates Dear ImGui as a programmable GUI which can be used later on to interact with the application. My hope is that this will eliminate some of the initial hesitation for people who want to learn Vulkan. This post is going to become a part of a series of entries that will describe how I approached the writing of deferred Vulkan renderer, so stay tuned for future posts. ","date":"01-09-2020","objectID":"/posts/vulkan-sandbox/:1:0","tags":["computer-graphics","vulkan","dear-imgui"],"title":"A Vulkan + Dear ImGui Sandbox","uri":"/posts/vulkan-sandbox/"},{"categories":null,"content":"Prerequisites I am going to assume that you have familiarized yourself with some of the terminology from the Vulkan API and have experience writing a C++ application. I will not be going into all of the technical details for Vulkan or Dear ImGui, so if you want to read up on any topics discussed in this post I recommend you take a look at the References section. ","date":"01-09-2020","objectID":"/posts/vulkan-sandbox/:2:0","tags":["computer-graphics","vulkan","dear-imgui"],"title":"A Vulkan + Dear ImGui Sandbox","uri":"/posts/vulkan-sandbox/"},{"categories":null,"content":"Installation For the installation I am going to assume you are working in a Linux environment, but all of the instructions should be easily transferable to other platforms. ","date":"01-09-2020","objectID":"/posts/vulkan-sandbox/:3:0","tags":["computer-graphics","vulkan","dear-imgui"],"title":"A Vulkan + Dear ImGui Sandbox","uri":"/posts/vulkan-sandbox/"},{"categories":null,"content":"Dependencies I tried to keep the number of dependencies as low as possible, so that it is easy for any user to tailor the codebase to their own needs. However, in order to compile the code right off the bat you will need: A C++14 compiler toolchain CMake (3.16) Vulkan SDK (1.2) GLFW (3.3) All of these dependencies are mandatory except for GLFW, which can be swapped out for another preferred cross-platform I/O handling library. ","date":"01-09-2020","objectID":"/posts/vulkan-sandbox/:3:1","tags":["computer-graphics","vulkan","dear-imgui"],"title":"A Vulkan + Dear ImGui Sandbox","uri":"/posts/vulkan-sandbox/"},{"categories":null,"content":"Building Once you have installed all of the necessary dependencies you can download a copy of the repository or clone it using the following command: git clone https://github.com/tstullich/vk-sandbox After the download finishes change to the root of the repository, where you can build the source code: mkdir build cd build cmake .. make If everything was built correctly, the renderer binary should be contained within the /build/cmake-build-debug/src directory. One important last step is to compile the GLSL shaders into SPIR-V binaries, which need to be loaded by the renderer at runtime. Contained within the shaders/ directory is a script called compile.sh that can be executed to compile the shaders. The script uses the glslangValidator from the Vulkan SDK, so make sure that the binary is visible through your $PATH variable. The compiled .spv binary files should be contained within the same directory, if the compilation was successful. Now you should have everything in place to run the program. Executing the renderer binary from the root directory should give you an output window with a triangle and UI as shown below. The first Vulkan triangle and Dear ImGui ","date":"01-09-2020","objectID":"/posts/vulkan-sandbox/:3:2","tags":["computer-graphics","vulkan","dear-imgui"],"title":"A Vulkan + Dear ImGui Sandbox","uri":"/posts/vulkan-sandbox/"},{"categories":null,"content":"Code Structure The code for the renderer is located in application.h and application.cpp and is purposefully kept in one class, so that it is easy to overview all of the components. This should also make it easier to break up the components to be more compartmentalized in the future. The logic in the code revolves mainly around initializing all of the necessary components for the Vulkan pipeline and UI, and then running a rendering loop until the user exits the program. What follows is a brief description of what goes into these parts. ","date":"01-09-2020","objectID":"/posts/vulkan-sandbox/:4:0","tags":["computer-graphics","vulkan","dear-imgui"],"title":"A Vulkan + Dear ImGui Sandbox","uri":"/posts/vulkan-sandbox/"},{"categories":null,"content":"Initialization Within the Application constructor lies the entry point to all of the logic that is needed to initialize the renderer. Starting off the initialization process is the initVulkan function that contains all of the logic for setting up the Vulkan pipeline. void Application::initVulkan() { createInstance(); setupDebugMessenger(); createSurface(); physicalDevice = pickPhysicalDevice(); getDeviceQueueIndices(); createLogicalDevice(); createSwapchain(); createImageViews(); createRenderPass(); createGraphicsPipeline(); createFramebuffers(); createCommandPool(); createCommandBuffers(); createSyncObjects(); createDescriptorPool(); } Some components have a strict dependency on one another, so the ordering of the function calls is quite important. Although I had Vulkan’s validation layers enabled from the start, some errors could not be caught by them. This led to segmentation faults at runtime, which would occur when passing invalid Vulkan handles to vkCreate() functions. However, the Vulkan API is designed to follow strictly the same function call pattern, which makes it easy to handoff the necessary data. All of the renderer’s createSomething() functions follow more or less the same pattern of: Create a VK_COMPONENT struct Fill the struct with the necessary data Hand off the information struct to a vkCreate() function Check the VK_RESULT if the function call succeeded This repeated pattern is also the source of the great amount of boilerplate code. If you take a closer look at the code, you will find that a majority of it is occupied with creating and setting the data fields of the structs provided by the Vulkan API. This might be intimidating at first if you are unfamiliar with the API, but once you spend some time writing the code it actually becomes an easily repeated pattern. ","date":"01-09-2020","objectID":"/posts/vulkan-sandbox/:4:1","tags":["computer-graphics","vulkan","dear-imgui"],"title":"A Vulkan + Dear ImGui Sandbox","uri":"/posts/vulkan-sandbox/"},{"categories":null,"content":"Loading Shaders A class to load SPIR-V shader code can also be found in shaderloader.h. Make sure to recompile the shaders if any changes are made to them. There is a way to hook the execution of the shader compile script into the build process using CMake, but at the time of writing this post this is not supported by the sandbox. ","date":"01-09-2020","objectID":"/posts/vulkan-sandbox/:4:2","tags":["computer-graphics","vulkan","dear-imgui"],"title":"A Vulkan + Dear ImGui Sandbox","uri":"/posts/vulkan-sandbox/"},{"categories":null,"content":"User Interface Getting Dear ImGui setup was trickier than writing the code for the renderer. The documentation for Dear ImGui is quite scattered and at times nonexistent, so finding reliable information on how to integrate the library with Vulkan took more time than expected. Luckily, I came across François Guthmann’s blog, which has a lot of useful information on how to solve this problem. I have linked it below in the References section if you are interested in more details. The initUI function contains all of the logic initialize Dear ImGui for rendering. void Application::initUI() { IMGUI_CHECKVERSION(); ImGui::CreateContext(); ImGui::StyleColorsDark(); // Initialize some DearImgui specific resources createUIDescriptorPool(); createUIRenderPass(); createUICommandPool(\u0026uiCommandPool, VK_COMMAND_POOL_CREATE_RESET_COMMAND_BUFFER_BIT); createUICommandBuffers(); createUIFramebuffers(); // Provide bind points from Vulkan API ImGui_ImplGlfw_InitForVulkan(window, true); ImGui_ImplVulkan_InitInfo init_info = {}; init_info.Instance = instance; init_info.PhysicalDevice = physicalDevice; init_info.Device = logicalDevice; init_info.QueueFamily = queueIndices.graphicsFamilyIndex; init_info.Queue = graphicsQueue; init_info.DescriptorPool = uiDescriptorPool; init_info.MinImageCount = imageCount; init_info.ImageCount = imageCount; ImGui_ImplVulkan_Init(\u0026init_info, uiRenderPass); // Upload the fonts for DearImgui VkCommandBuffer commandBuffer = beginSingleTimeCommands(uiCommandPool); ImGui_ImplVulkan_CreateFontsTexture(commandBuffer); endSingleTimeCommands(commandBuffer, uiCommandPool); ImGui_ImplVulkan_DestroyFontUploadObjects(); } The main realization I had to make was that Dear ImGui requires a number of extra resources, that were not immediately available in my initial code. Dear ImGui requires the user to setup an extra set of framebuffers, a render pass, and command buffers which in turn required the allocation of a command and descriptor pool. I was under the impression that I could reuse my command buffers and integrate some extra logic into the main render pass to make Dear ImGui work, but this is not the case. Without these resources the renderer would repeatedly crash at runtime, which was frustrating to debug. Once the extra resources had been created, integrating the UI into the rendering loop was quite simple. All that had to be done was to fill out the ImGui_ImplVulkan_InitInfo struct and call the corresponding Dear ImGui helper functions, which took over the rest of the initialization. ","date":"01-09-2020","objectID":"/posts/vulkan-sandbox/:4:3","tags":["computer-graphics","vulkan","dear-imgui"],"title":"A Vulkan + Dear ImGui Sandbox","uri":"/posts/vulkan-sandbox/"},{"categories":null,"content":"Rendering Loop Now that all the necessary components are setup and ready to run, the main rendering loop takes over. With the bulk of the code being dedicated to initializing the state of the Vulkan pipeline, it should come as no surprise that the actual rendering portion is comparatively short. The rendering loop is triggered through the run function, where we poll GLFW for any input events from the keyboard, build the UI components in drawUI and eventually reach the drawFrame function, which contains the main logic to render and present one frame. Drawing a frame requires the following operations: Wait for the current frame’s fences Acquire the next presentable image from the swapchain Mark the current image as being in use Record Dear ImGui’s command buffer Submit the command buffers to the graphics queue Submit the image to the presentation queue These steps are then executed at each loop iteration until the user exits the program. ","date":"01-09-2020","objectID":"/posts/vulkan-sandbox/:4:4","tags":["computer-graphics","vulkan","dear-imgui"],"title":"A Vulkan + Dear ImGui Sandbox","uri":"/posts/vulkan-sandbox/"},{"categories":null,"content":"Wrapup Hopefully this post has given you a broad overview of what it takes to get started in writing a Vulkan application. Of course there is more code in the sandbox that I have not touched on, but at least you should be comfortable in navigating the code and have a feeling for the structure of a Vulkan application. If you have any questions, drop a comment below and I will try to answer it as soon as possible. ","date":"01-09-2020","objectID":"/posts/vulkan-sandbox/:5:0","tags":["computer-graphics","vulkan","dear-imgui"],"title":"A Vulkan + Dear ImGui Sandbox","uri":"/posts/vulkan-sandbox/"},{"categories":null,"content":"References Here I have listed some links, which have helped me a lot in learning more about Vulkan and Dear ImGui. Perhaps they will be useful to you as well. vulkan-tutorial.com - Step-by-step introduction to writing a Vulkan renderer. Vulkan Specification - The Vulkan specification is a great resource for in-depth details of Vulkan. Dear ImGui Documentation - For more information on how to customize the UI. François Guthmann’s blog - A great blog post on how to integrate Dear ImGui into a Vulkan application. ","date":"01-09-2020","objectID":"/posts/vulkan-sandbox/:6:0","tags":["computer-graphics","vulkan","dear-imgui"],"title":"A Vulkan + Dear ImGui Sandbox","uri":"/posts/vulkan-sandbox/"},{"categories":null,"content":"Download Link If you wish to use this sandbox project for your own projects, feel free to download the code from my Github. ","date":"01-09-2020","objectID":"/posts/vulkan-sandbox/:7:0","tags":["computer-graphics","vulkan","dear-imgui"],"title":"A Vulkan + Dear ImGui Sandbox","uri":"/posts/vulkan-sandbox/"},{"categories":null,"content":"A personal introduction to myself and the goals for this website/blog.","date":"01-09-2020","objectID":"/posts/introduction/","tags":["introduction","personal"],"title":"Hello! :)","uri":"/posts/introduction/"},{"categories":null,"content":"Thanks for being here! As this is my first blog post, I would like to introduce myself and set the expectations of what you, the reader, can expect from this blog. Who Am I? My name is Tim Stullich and I am a Software Developer based out of Berlin, Germany. I started off my journey in Computer Science when I began my Bachelor’s studies at San Jose State University in 2010. During my undergraduate years I mainly focused on Software Development towards mobile applications and writing web services. After receiving my Bachelor’s degree, I spent some time working at Amazon Web Services as a Software Developer before moving back to Germany to study for a Master’s degree. Now that I have recently completed my studies, I am currently looking for work and decided to spend my trying out some new hobbies, such as starting a blog. As this is my first foray into “creative” writing since my undergrad years, there are bound to be some growing pains as I continue to try to improve my content. I do not consider myself an excellent writer, so if you have any constructive feedback, please do not hesitate to reach out to me with suggestions. Motivation This website is meant to serve two general purposes: As a learning tool for myself and anyone interested in the topics I write about A centralized portfolio of my work which others can draw inspiration from Generally, I am going to write on topics that currently hold my interest, with the hopes that someone will stumble across this blog at some point and gain some useful knowledge from it. Because I am also fairly new to the computer graphics space, information on this blog might not be 100% accurate, although I will give my best to present accurate information in my posts. Post Frequency Because I may not always have time to dedicate myself to writing, the frequency with which I post is going to be fairly sporadic. I am going to aim to publish at least one article a month, but I do not intend to keep that as a hard requirement. I want to create content that I would enjoy reading myself so I want to stick to the “quality over quantity” mantra. ","date":"01-09-2020","objectID":"/posts/introduction/:0:0","tags":["introduction","personal"],"title":"Hello! :)","uri":"/posts/introduction/"},{"categories":null,"content":"Thanks for visiting my website. My name is Tim Stullich and I am a Software Developer with a Master’s degree in Computer Science. My main interests revolve around computer graphics and machine learning, so most of the content on this website will be focused towards these subjects. I do have plans to write about less scientific topics though. I am also a big fan of video and board games, which have shaped a large part of my upbringing. When I am not in front of the computer I tend to be outdoors spending my time playing football (not the American kind :D) and discovering Munich where I currently live. If you are interested in checking out my work, please take a look at the Portfolio section. Contact Information I am always interested in hearing from people. If you have any feedback or would like to get in touch with me, feel free to send me a message on Twitter or LinkedIn and follow my projects on Github. ","date":"01-01-0001","objectID":"/about/:0:0","tags":null,"title":"About Me","uri":"/about/"},{"categories":null,"content":"All of the source code for the listed projects can be viewed on my Github profile or you can find a link to each individual repository at the bottom of each project. Personal Projects ","date":"01-01-0001","objectID":"/portfolio/:0:0","tags":[],"title":"Portfolio","uri":"/portfolio/"},{"categories":null,"content":"1. Vulkan Deferred Renderer C++ Vulkan GLSL C++ Dear ImGui Rendering GUI Shaders A snapshot of a model loaded with the renderer I attempted to build out a deferred renderer using Vulkan and Dear ImGui. My intent was to improve my knowledge around Vulkan and realtime rendering, while also providing a way for others to see what it’s like building a renderer from scratch. I have mostly abandoned this project now, but I am intending to repurpose it for an upcoming project, which I will provide more information in future blog posts. The source code to the basic setup has been published here. ","date":"01-01-0001","objectID":"/portfolio/:1:0","tags":[],"title":"Portfolio","uri":"/portfolio/"},{"categories":null,"content":"2. Odin - A Vulkan-based Path Tracer C++ GLSL Vulkan Realtime Rendering Shaders This project was my first step into getting my feet wet with the Vulkan API. When NVIDIA announced their first GPU series featuring the Turing architecture, I decided to test if it was possible to write a real-time raytracing application without a dedicated GPU. The renderer uses a single compute shader to perform the path tracing algorithm and write the result into a texture image which can be sampled from the graphics pipeline. It also sports the following features: Support for diffuse, caustic, and dielectric materials Tracing of geometry serialized in the OBJ file format A basic Bounding Volume Hierarchy using axis-aligned bounding boxes Overall, the implementation is still quite bottlenecked due to the fact that there are a lot of branching instructions, which only lets the renderer run at around 10-20 FPS on my hardware. If I could spend some time optimizing my shader code, I could envision the renderer having more practical applications. The source code can be found here. ","date":"01-01-0001","objectID":"/portfolio/:2:0","tags":[],"title":"Portfolio","uri":"/portfolio/"},{"categories":null,"content":"3. Raytracing In One Weekend In Rust Rust Raytracing An image created with the Rust path tracer at 1200x800 resolution and 1024spp As a challenge to myself to learn Rust, I decided to adapt Peter Shirley’s Raytracing In One Weekend tutorial, which is written in C++, into a Rust application. All of the features from the first book are available including some extras: OBJ model parsing or randomized scene creation Support for configurable dielectric, diffuse, and caustic materials Motion blur Checkered textures support Configuring of rendering parameters through command line arguments Multithreaded rendering through the use of Rust’s rayon library The source code can be found here. Academic Projects ","date":"01-01-0001","objectID":"/portfolio/:3:0","tags":[],"title":"Portfolio","uri":"/portfolio/"},{"categories":null,"content":"1. Master’s Thesis On Differentiable Rendering C++ Python Differentiable Rendering Machine Learning Differentiable rendering tries to minimize the loss between two images by applying gradient descent For my Master’s thesis I decided to explore differentiable rendering, which combines machine learning with computer graphics. For a good explanation on the topic I encourage you to watch Wenzel Jakob’s Keynote Speech during the High Performance Graphics 2020 conference. In my case, I chose to extend the capabilities of the differentiable renderer redner, which was introduced by Li et al. in the paper Differentiable Monte Carlo Ray Tracing through Edge Sampling, to be able to optimize homogeneous participating media. The figure above shows one of the test setups that was used to verify the code that I had written. The perturbed scene on the left-hand side is enveloped in a thick fog and the goal of the test run was to remove the fog entirely by optimizing the scene towards the target image on the right-hand side. The result of running the gradient descent optimization can be seen in the figure below. The fog has been nearly removed from the perturbed image, with some visual artifacts remaining in the tree line in the background. A capture of the results from optimizing homogeneous participating media through redner For more details on my thesis please read through my thesis presentation or contact me directly for a copy of the full thesis. The source code can be found here. ","date":"01-01-0001","objectID":"/portfolio/:4:0","tags":[],"title":"Portfolio","uri":"/portfolio/"},{"categories":null,"content":"3. Computer Graphics 2 (TU Berlin) OpenGL Qt5 Data Structures Surface Reconstruction Implicit Surfaces The Computer Graphics 2 course taught a number of different techniques focused around geometric reconstruction and implicit surfaces. All of the assignments focused on a particular topic within those domains and were completed in collaboration with two group members. For the coding portions of the assignments we used OpenGL to perform our graphics computations, with Qt5 acting as the framework for the demos’ user interface. Qt5 allowed us to dynamically adjust the parameters for the various demonstrations. What follows are some of the highlights of the course. ","date":"01-01-0001","objectID":"/portfolio/:5:0","tags":[],"title":"Portfolio","uri":"/portfolio/"},{"categories":null,"content":"K-d Trees With Nearest Neighbor Point Search The k-d tree data structure being used to perform k-nearest neighbor search on a point cloud This assignment revolved around building a k-d tree data structure, which acts as a binary tree data structure for k-dimensional point sets. This is accomplished by partitioning the k-dimensional (k=3 in our case) spatial domain into a half-space. To find a dividing plane for the half-space, the points in our data sets were sorted using a quicksort algorithm, which I implemented from scratch for efficient sorting. The k-d tree was then used in our application to implement a N-Nearest Neighbor Search algorithm to collect an arbitrary set of points near a point in space. The image above shows how a user can select a point in the data set, and the nearest neighbor search then gathers of a preset amount of points in its neighborhood. The selected point is highlighted in pink and the n-closest points (N=1617) are shown in green. ","date":"01-01-0001","objectID":"/portfolio/:5:1","tags":[],"title":"Portfolio","uri":"/portfolio/"},{"categories":null,"content":"Surface Reconstruction Using Marching Cubes The model in this picture is represented by a point cloud implicit surface implementation This assignment focused on surface reconstruction using the marching cubes algorithm. From the implicit surface representation, shown in the above image, a 3D cube is marched along an adjustable fixed grid. At each step, we test what parts of the cube’s surface is inside or outside of the volume by intersecting a set of 256 precomputed triangle configurations with the surface. If an intersection is found, a triangle is constructed through the three intersection points of the cube with the surface and added to a mesh data structure. The reconstructed surface model through the use of a Marching Cubes algorithm One such mesh, which was created after one run of the marching cubes algorithm, can be seen above. Although the mesh is not a perfect representation of the surface, it is possible to create finer approximations by adjusting the grid subdivision and tuning the nearest neighbor search parameters. The source code for these projects can be found here. ","date":"01-01-0001","objectID":"/portfolio/:5:2","tags":[],"title":"Portfolio","uri":"/portfolio/"},{"categories":null,"content":"4. Computer Graphics 1 (TU Berlin) JavaScript WebGL Shaders Scene Graphs A WebGL ray tracer that I wrote as part of my studies in CG1 The very first course that I took for computer graphics was the CG 1 course taught at the Technical University Berlin. This was an introductory course which covered a classical forward rendering pipeline from front to back. Among the topics covered were: Scene graph representations and linear transformations Camera projections Texture mapping Various shading techniques (Gourad, Phong, etc.) Color theory The final assignment for the course is what convinced me to focus on rendering. The assignment let us write a ray tracer in WebGL which produced the output image seen above. The simplicity of the ray tracing algorithm, along with the stunning output it provides drove me to learn more about the subject and soon enough I was deep into the rabbit hole on rendering. The source code for the ray tracer as well as the other projects can be found here. Conference Papers ","date":"01-01-0001","objectID":"/portfolio/:6:0","tags":[],"title":"Portfolio","uri":"/portfolio/"},{"categories":null,"content":"EDBT 2019 Demonstration Paper Publication C++ Scientific Writing IoT Sensor Networks During my time as a Student Research Assistant with the Database Systems and Information Management Group at the Technical University in Berlin, I got the chance to work on a demonstration paper that was presented at the Extending Database Technology conference in 2019. The work was focused on recording and replaying sensor data on IoT devices. The abstract for the paper has been cited below: As the scientific interest in the Internet of Things (IoT) continues to grow, emulating IoT infrastructure involving a large number of heterogeneous sensors plays a crucial role. Existing research on emulating sensors is often tailored to specific hardware and/or software, which makes it difficult to reproduce and extend. In this paper we show how to emulate different kinds of sensors in a unified way that makes the downstream application agnostic as to whether the sensor data is acquired from real sensors is read from memory using emulated sensors. We propose the Resense framework that allows for replaying sensor data using emulated sensors and provides an easy-to-use software for setting up and executing IoT experiments involving a large number of heterogeneous sensors. We demonstrate various aspects of Resense in the context of a sports analytics application using real-world sensor data and a set of Raspberry Pis. – Resense: Transparent Record and Replay of Sensor Data in the Internet of Things The full paper can be read here. ","date":"01-01-0001","objectID":"/portfolio/:7:0","tags":[],"title":"Portfolio","uri":"/portfolio/"}]